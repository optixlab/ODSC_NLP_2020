{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "1. https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_11_01_spacy.ipynb\n",
    "2. https://derwen.ai/s/d5c7#1\n",
    "3. [SpaCy Universe](https://spacy.io/universe) (ref: [derwen.ai](https://derwen.ai/s/d5c7#1))\n",
    " - [Legal: Blackstone](https://spacy.io/universe/project/blackstone)\n",
    " - [Biomedical: Kindred](https://spacy.io/universe/project/kindred)\n",
    " - [Geographic: mordecai](https://spacy.io/universe/project/mordecai)\n",
    " - [Label: Prodigy](https://spacy.io/universe/project/prodigy)\n",
    " - [Edge: spacy-raspberry](https://spacy.io/universe/project/spacy-raspberry)\n",
    " - [Voice: Rasa NLU](https://spacy.io/universe/project/rasa) \n",
    "  - [Transformers: spacy-transformers](https://explosion.ai/blog/spacy-pytorch-transformers) \n",
    "  - [Conference: spaCy IRL 2019](https://irl.spacy.io/2019/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[00mUsing Google CoLab = \u001b[93mFalse\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    !pip install spacy\n",
    "    !python -m spacy download en_core_web_lg\n",
    "    !pip install spacy-transformers\n",
    "except:\n",
    "    COLAB = False\n",
    "\n",
    "print(f'\\033[00mUsing Google CoLab = \\033[93m{COLAB}')\n",
    "if (COLAB): print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy: Getting started\n",
    "\n",
    "As discussed in the lecture portion, Python has two main libraries to help with NLP tasks: \n",
    "\n",
    "* [NLTK](https://www.nltk.org/)\n",
    "* [Spacy](https://spacy.io/)\n",
    "\n",
    "SpaCy launched in 2015 and has rapidly become an industry standard, and is a focus of our training. SpaCy provides an industrial grade project that is both open-source and contains community driven integrations (see SpaCy Universe).\n",
    "\n",
    "SpaCy requires you to download language resources (such as models). For the english language, you can use `python -m spacy download en_core_web_sm`. The suffix `_sm` indicates \"small\" model, while `_md` and `_lg` indicate medium and large, respectively and provide more advanced features (we won't need in this tutorial).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Use if needed:\n",
    "#spacy.util.get_data_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "For each word in that sentence _spaCy_ generates a [token](https://spacy.io/api/token) for each word in the sentence. The token fields show the raw text, the root of the word (lemma), the Part of Speech (POS), whether or not its a stop word, and many other things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this DET DT nsubj xxxx True True\n",
      "is be AUX VBZ ROOT xx True True\n",
      "a a DET DT det x True True\n",
      "beautiful beautiful ADJ JJ amod xxxx True False\n",
      "day day NOUN NN attr xxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "text = \"this is a beautiful day\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric representation\n",
    "\n",
    "Let's print the last token and see its _numeric_ representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token is from the raw text: \u001b[92mday\u001b[0m\n",
      "Numeric representation:\n",
      "\n",
      "[ 1.639962   -1.5621606   0.05948496  0.01268986  2.1984892  -1.8145177\n",
      " -0.745441   -1.5280969  -2.7714853   6.007323   -2.0809193  -1.961708\n",
      "  2.1664617   2.3318393  -3.8029075  -2.745814    1.7596581   2.5324426\n",
      " -0.5090674   2.0728378   3.501279   -0.88496184  1.6712112  -0.8527437\n",
      "  0.81122905  3.8929913  -2.6595979  -1.4807723   0.9421574   1.870143\n",
      " -0.76680666 -0.9048741   0.51840436 -1.8099762  -3.7449381   1.1266654\n",
      " -1.5931005   0.6592519   2.1718125   1.0615923   1.2269886  -2.0375106\n",
      " -2.7071342  -0.96021605  2.1439214  -2.8734689   0.4292348  -2.465563\n",
      " -1.6698704  -0.94421875 -1.5220733  -0.22063437 -0.77889663 -2.4767165\n",
      "  1.944675    2.2797525   0.55317724 -2.6973386  -0.9994705  -1.3853178\n",
      " -0.9034357  -2.038024    0.46580553 -1.2795513   1.4021541   3.738821\n",
      "  3.2633476  -1.2171834   2.8708591   4.098246   -2.5814586   0.7266145\n",
      "  1.4873066  -0.0491671  -0.8378353   2.0663633   2.8921773   0.6389611\n",
      " -3.2981458  -1.449377   -1.2674084  -0.02590978  1.6254084  -1.7930709\n",
      "  1.0516669  -0.5186747   1.856763   -0.29712042 -1.1916928   0.5798759\n",
      " -1.4933081  -1.0668793   1.2417698   0.68111956  2.0910163  -0.775237  ]\n",
      "\n",
      "The length of the vector is (96,)\n"
     ]
    }
   ],
   "source": [
    "print(f'The token is from the raw text: \\033[92m{token.text}\\033[0m\\nNumeric representation:\\n')\n",
    "print(token.vector)\n",
    "print(f'\\nThe length of the vector is {token.vector.shape}') # 96 length vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display\n",
    "\n",
    "Note: Run the following as `display.serve` outside of Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"29f028bab5ac412e8771a01a97cb3312-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">today</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">bright</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">sunny</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-29f028bab5ac412e8771a01a97cb3312-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-29f028bab5ac412e8771a01a97cb3312-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-29f028bab5ac412e8771a01a97cb3312-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-29f028bab5ac412e8771a01a97cb3312-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-29f028bab5ac412e8771a01a97cb3312-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-29f028bab5ac412e8771a01a97cb3312-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-29f028bab5ac412e8771a01a97cb3312-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-29f028bab5ac412e8771a01a97cb3312-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " is bright and sunny</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "displacy.render(doc, style=\"ent\")\n",
    "# day is shown as a recognized \"DATE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Explore different parts of speech & sentence structures. \n",
    "* Show PERSON \n",
    "* Show location\n",
    "\n",
    "Some examples:\n",
    "* \"They met at a cafe in London last year\"\n",
    "* \"Peter went to see his uncle in Brooklyn\"\n",
    "* \"The chicken crossed the road because it was hungry\"\n",
    "* \"The chicken crossed the road because it was narrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of two sentences\n",
    "\n",
    "Let's do the same as above, but mix with two similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\"this is a beautiful day\", \"today is bright and sunny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_list = list(map(nlp, sentence_list))\n",
    "doc_list = list(nlp.pipe(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mPrinting tokens for \u001b[91m\"this is a beautiful day\"\u001b[0m\n",
      "    text             lemma            pos    tag    dep    shape       is_alpha    is_stop\n",
      "--  ---------------  ---------------  -----  -----  -----  ----------  ----------  ---------\n",
      " 0  this             this             DET    DT     nsubj  xxxx        True        True\n",
      " 1  is               be               AUX    VBZ    ROOT   xx          True        True\n",
      " 2  a beautiful day  a beautiful day  NOUN   NN     attr   x xxxx xxx  False       False\n",
      "\n",
      "\u001b[92mPrinting tokens for \u001b[91m\"today is bright and sunny\"\u001b[0m\n",
      "    text             lemma            pos    tag    dep    shape       is_alpha    is_stop\n",
      "--  ---------------  ---------------  -----  -----  -----  ----------  ----------  ---------\n",
      " 0  this             this             DET    DT     nsubj  xxxx        True        True\n",
      " 1  is               be               AUX    VBZ    ROOT   xx          True        True\n",
      " 2  a beautiful day  a beautiful day  NOUN   NN     attr   x xxxx xxx  False       False\n",
      " 3  today            today            NOUN   NN     nsubj  xxxx        True        False\n",
      " 4  is               be               AUX    VBZ    ROOT   xx          True        True\n",
      " 5  bright           bright           ADJ    JJ     acomp  xxxx        True        False\n",
      " 6  and              and              CCONJ  CC     cc     xxx         True        True\n",
      " 7  sunny            sunny            ADJ    JJ     conj   xxxx        True        False\n"
     ]
    }
   ],
   "source": [
    "## Python program to understand the usage of tabulate function for printing tables in a tabular format\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "column_names = ['text', 'lemma', 'pos', 'tag', 'dep', 'shape', 'is_alpha', 'is_stop']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "for doc in doc_list:\n",
    "    print(f'\\n\\033[92mPrinting tokens for \\033[91m\"{doc}\"\\033[0m')\n",
    "    for token in doc:\n",
    "        token_list = [token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                      token.shape_, token.is_alpha, token.is_stop]\n",
    "        token_series = pd.Series(token_list, index = df.columns)\n",
    "        df = df.append(token_series, ignore_index=True)\n",
    "    print(tabulate(df, headers=column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing similarity between two sentences\n",
    "\n",
    "1. \"this is a beautiful day\"\n",
    "2. \"this day is bright and sunny\"\n",
    "\n",
    "Note: If you have loaded the small (sm) dataset, you will get the following warning:\n",
    "> UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
    "\n",
    "Try: \n",
    "* `python -m spacy download en_core_web_md`\n",
    "* or: `python -m spacy download en_core_web_lg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# choose action = 'ignore' to ignore the small dataset warning\n",
    "warnings.filterwarnings(action = \"ignore\") # \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232043828276217"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[0].similarity(doc_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_md = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7740792555658819"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try again\n",
    "doc_md_list = list(map(nlp_md, sentence_list))\n",
    "doc_md_list[0].similarity(doc_md_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph\n",
    "\n",
    "How do you deal with multiple sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> When we went out for ice-cream last summer, the place was \n",
      "packed.\n",
      "> This year, however, things are eerily different.\n",
      "> You can see that \n",
      "the stores are nearly desserted and roads empty like never before.\n",
      "> It's a \n",
      "reality that we are all getting used to, albeit very slowly and reluctantly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"When we went out for ice-cream last summer, the place was \n",
    "packed. This year, however, things are eerily different. You can see that \n",
    "the stores are nearly desserted and roads empty like never before. It's a \n",
    "reality that we are all getting used to, albeit very slowly and reluctantly.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(\">\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattertext\n",
    "\n",
    "Credit: derwen.ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # install if not already run\n",
    "    !pip install scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "\n",
    "if \"merge_entities\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_entities\"))\n",
    "\n",
    "if \"merge_noun_chunks\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(nlp.create_pipe(\"merge_noun_chunks\"))\n",
    "\n",
    "convention_df = st.SampleCorpora.ConventionData2012.get_data() \n",
    "corpus = st.CorpusFromPandas(convention_df,\n",
    "                             category_col=\"party\",\n",
    "                             text_col=\"text\",\n",
    "                             nlp=nlp).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate interactive visualization once the corpus is ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category=\"democrat\",\n",
    "    category_name=\"Democratic\",\n",
    "    not_category_name=\"Republican\",\n",
    "    width_in_pixels=1000,\n",
    "    metadata=convention_df[\"speaker\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use in Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use in Jupyter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"foo.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fee2b524198>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"foo.html\"\n",
    "\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(html.encode(\"utf-8\"))\n",
    "\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynlp",
   "language": "python",
   "name": "pynlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
